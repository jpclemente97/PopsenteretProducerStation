{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8c5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import keyboard\n",
    "import pandas as pd\n",
    "import os\n",
    "from pygrabber.dshow_graph import FilterGraph\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "if sys.version_info[0] == 2:\n",
    "    import Tkinter\n",
    "    tkinter = Tkinter\n",
    "else:\n",
    "    import tkinter\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eabf2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkCSV(filepath=None):\n",
    "    \n",
    "    if filepath == None:\n",
    "        \n",
    "        for file in os.listdir():\n",
    "            \n",
    "            if 'seq.csv' in file:\n",
    "                \n",
    "                return 1\n",
    "                \n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for file in os.listdir(filepath):\n",
    "            \n",
    "            if 'seq.csv' in file:\n",
    "                \n",
    "                return 1\n",
    "            \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d2fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoThreshold():\n",
    "    \n",
    "    hole_positions = loadSequence()\n",
    "    \n",
    "    snapshot = takeSnapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1570ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSequence(filepath=None):\n",
    "    \n",
    "    seq_array = np.empty(40, dtype=object)\n",
    "    \n",
    "    if filepath == None:\n",
    "        \n",
    "        seq_csv = pd.read_csv('seq.csv', header=None)\n",
    "        \n",
    "        for idx, (x, y) in enumerate(zip(seq_csv[0], seq_csv[1])):\n",
    "            \n",
    "            seq_array[idx] = (x, y)\n",
    "            \n",
    "        seq_array = np.reshape(seq_array, [5, 8])\n",
    "        \n",
    "        return seq_array\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        seq_csv = pd.read_csv(filepath + '/seq.csv', header=None)\n",
    "        \n",
    "        for idx, (x, y) in enumerate(zip(seq_csv[0], seq_csv[1])):\n",
    "            \n",
    "            seq_array[idx] = (x, y)\n",
    "            \n",
    "        seq_array = np.reshape(seq_array, [5, 8])\n",
    "        \n",
    "        return seq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f97a421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking snapshot from camera\n",
      "This can take some time\n",
      "Obtaining video capture device...\n",
      "Video capture device obtained\n",
      "Setting frame width...\n",
      "Frame width set\n",
      "Setting frame height...\n",
      "Frame height set\n",
      "<class 'numpy.uint8'>\n",
      "blongo\n"
     ]
    }
   ],
   "source": [
    "takeSnapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a24ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeSnapshot():\n",
    "    \n",
    "    print('Taking snapshot from camera')\n",
    "    print('This can take some time')\n",
    "    \n",
    "    camera = 'cam300'\n",
    "    \n",
    "    device_idx = getDeviceIndex(camera)\n",
    "    \n",
    "    print('Obtaining video capture device...')\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    print('Video capture device obtained')\n",
    "    \n",
    "    num_frames = 2\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = frame.astype(np.uint8)\n",
    "        frame  = rgb2Luma(frame)\n",
    "        frames.append(frame)\n",
    "        \n",
    "#         cv2.imshow('image',frame)\n",
    "#         cv2.waitKey(5000)\n",
    "#         cv2.destroyAllWindows()\n",
    "        \n",
    "    frames = np.array(frames)\n",
    "    \n",
    "    slideval = 2\n",
    "    \n",
    "    snapshot = framesSlide(frames, slideval)\n",
    "    \n",
    "    cv2.imshow('image',snapshot)\n",
    "    cv2.waitKey(10000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072cea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDeviceIndex(camera=''):\n",
    "    \n",
    "    graph = FilterGraph()\n",
    "    \n",
    "    devices = graph.get_input_devices()\n",
    "    \n",
    "    for idx, device in enumerate(devices):\n",
    "        \n",
    "        if camera.lower() in device.lower():\n",
    "            \n",
    "            return idx\n",
    "            \n",
    "    print('Camera device index not found')\n",
    "    print('Please check name of camera is correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "544f74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2Luma(frame):\n",
    "    \n",
    "    blue = frame[:,:,0]\n",
    "    green = frame[:,:,1]\n",
    "    red = frame[:,:,2]\n",
    "    \n",
    "    blue = blue*0.114\n",
    "    green = green*0.587\n",
    "    red = red*0.299\n",
    "    \n",
    "    luma = blue + green + red\n",
    "    \n",
    "    luma = luma.astype(np.uint8)\n",
    "    \n",
    "    return luma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d687c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def framesSlide(frames, slideval):\n",
    "    \n",
    "    output_frames = []\n",
    "    \n",
    "    dummy_frame = np.empty(frames[0].shape, dtype=np.uint8)\n",
    "    \n",
    "    dummy_frame.fill(255)\n",
    "    \n",
    "    output_frames.append(dummy_frame)\n",
    "    \n",
    "    print(type(frames[0][0][0]))\n",
    "    \n",
    "    for i in range(0, len(frames)):\n",
    "        \n",
    "        print(len(output_frames))\n",
    "        \n",
    "        #y(n) = y (n-1) + ( (x (n) - y (n-1))  /slide ) \n",
    "        \n",
    "        output_frame = output_frames[i] + ((frames[i]-output_frames[i])/slideval)\n",
    "        \n",
    "        output_frame = output_frame.astype(np.uint8)\n",
    "        \n",
    "        output_frames.append(output_frame)\n",
    "        \n",
    "    output_frames = np.array(output_frames)\n",
    "    \n",
    "    output_frames = output_frames[1]\n",
    "    \n",
    "    return output_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0082c747",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ANTIALIAS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdisplayPegs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mdisplayPegs\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filepath \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCameraCalibrating.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mshowPIL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m, in \u001b[0;36mshowPIL\u001b[1;34m(pilImage)\u001b[0m\n\u001b[0;32m     16\u001b[0m     imgWidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(imgWidth\u001b[38;5;241m*\u001b[39mratio)\n\u001b[0;32m     17\u001b[0m     imgHeight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(imgHeight\u001b[38;5;241m*\u001b[39mratio)\n\u001b[1;32m---> 18\u001b[0m     pilImage \u001b[38;5;241m=\u001b[39m pilImage\u001b[38;5;241m.\u001b[39mresize((imgWidth,imgHeight), \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANTIALIAS\u001b[49m)\n\u001b[0;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m ImageTk\u001b[38;5;241m.\u001b[39mPhotoImage(pilImage)\n\u001b[0;32m     20\u001b[0m imagesprite \u001b[38;5;241m=\u001b[39m canvas\u001b[38;5;241m.\u001b[39mcreate_image(w\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,h\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,image\u001b[38;5;241m=\u001b[39mimage)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"
     ]
    }
   ],
   "source": [
    "displayPegs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70487f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayPegs(filepath=None):\n",
    "    \n",
    "    if filepath == None:\n",
    "        \n",
    "        image = Image.open('CameraCalibrating.png')\n",
    "        showPIL(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a07a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shamelessly stolen from https://stackoverflow.com/questions/47316266/can-i-display-image-in-full-screen-mode-with-pil\n",
    "\n",
    "def showPIL(pilImage):\n",
    "    root = tkinter.Tk()\n",
    "    w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "    root.overrideredirect(1)\n",
    "    root.geometry(\"%dx%d+0+0\" % (w/2, h/2))\n",
    "    root.focus_set()    \n",
    "    root.bind(\"<Escape>\", lambda e: (e.widget.withdraw(), e.widget.quit()))\n",
    "    canvas = tkinter.Canvas(root,width=w,height=h)\n",
    "    canvas.pack()\n",
    "    canvas.configure(background='black')\n",
    "    imgWidth, imgHeight = pilImage.size\n",
    "    if imgWidth > w or imgHeight > h:\n",
    "        ratio = min(w/imgWidth, h/imgHeight)\n",
    "        imgWidth = int(imgWidth*ratio)\n",
    "        imgHeight = int(imgHeight*ratio)\n",
    "        pilImage = pilImage.resize((imgWidth,imgHeight), Image.ANTIALIAS)\n",
    "    image = ImageTk.PhotoImage(pilImage)\n",
    "    imagesprite = canvas.create_image(w/2,h/2,image=image)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd06cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circleDetector():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c08238b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    found_csv = False\n",
    "    circle_detector_runs = 0\n",
    "    \n",
    "    while found_csv == False:\n",
    "        \n",
    "        if circle_detector_runs > 10:\n",
    "            \n",
    "            print('Error in circle detector')\n",
    "            print('Please direct all complaints towards Julius Jakoby-Pflug')\n",
    "            break\n",
    "    \n",
    "        print('Checking if circle detector sequence found...')\n",
    "\n",
    "        found_csv = checkCSV()\n",
    "\n",
    "        if found_csv == True:\n",
    "\n",
    "            print('Circle detector sequence found')\n",
    "            print('Running autothreshold...')\n",
    "\n",
    "            autoThreshold()\n",
    "\n",
    "        else:\n",
    "\n",
    "            print('Circle detector sequence not found')\n",
    "            print('Please place pegs into the holes indicated')\n",
    "            \n",
    "            displayPegs()\n",
    "            \n",
    "            print('Running circle detector...')\n",
    "\n",
    "            circleDetector()\n",
    "            \n",
    "            circle_detector_runs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10bf2fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if circle detector sequence found...\n",
      "Circle detector sequence found\n",
      "Running autothreshold...\n",
      "Taking snapshot from camera\n",
      "This can take some time\n",
      "Obtaining video capture device...\n",
      "Video capture device obtained\n",
      "Setting frame width...\n",
      "Frame width set\n",
      "Setting frame height...\n",
      "Frame height set\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 23\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCircle detector sequence found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning autothreshold...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mautoThreshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCircle detector sequence not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m, in \u001b[0;36mautoThreshold\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mautoThreshold\u001b[39m():\n\u001b[0;32m      3\u001b[0m     hole_positions \u001b[38;5;241m=\u001b[39m loadSequence()\n\u001b[1;32m----> 5\u001b[0m     snapshot \u001b[38;5;241m=\u001b[39m \u001b[43mtakeSnapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[86], line 33\u001b[0m, in \u001b[0;36mtakeSnapshot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_frames):\n\u001b[0;32m     32\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 33\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     34\u001b[0m     frame  \u001b[38;5;241m=\u001b[39m rgb2Luma(frame)\n\u001b[0;32m     35\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(frame)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de786414",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 1. take an image of sequencer\n",
    "    \n",
    "    # 2. load circle centres\n",
    "    \n",
    "    # 3. check to see if corner/centre holes differences are above value\n",
    "    \n",
    "    # 4a. if yes run auto-threshold\n",
    "    \n",
    "    # 4b. if no pop up window asking to place blocks\n",
    "    \n",
    "        # 4b.1. repeat 1.\n",
    "        \n",
    "        # 4b.2. repeat 3.\n",
    "        \n",
    "        # 4b.3a. if yes run auto-threshold\n",
    "        \n",
    "        # 4b.3b. if no pop-up window asking to check lighting conditions\n",
    "        \n",
    "            # 4b.3b.1. repeat 1.\n",
    "            \n",
    "            # 4b.3b.2. repeat 3.\n",
    "            \n",
    "            # 4b.3b.3a. if yes run auto-threshold\n",
    "            \n",
    "            # 4b.3b.3b. if no ask if want to proceed\n",
    "            \n",
    "                # 4b.3b.3b.1. if yes run auto-threshold\n",
    "                \n",
    "                # 4b.3b.3b.2. if no run auto-threshold anyway?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
